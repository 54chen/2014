<html class="no-js" lang="en">
<!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <title>五四陈科学院</title>
    <meta name="author" content="54chen">
  
    
    <meta name="description" content="Happy New Year! 2009-01-25 00:00:00 +0800 用iptables做本机端口转发 2009-01-23 00:00:00 +0800 代码如下： iptables -t nat -A PREROUTING -p tcp --dport 80 -j …">
    
  
    <!-- http://t.co/dKP3o1e -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  
    
    <link rel="canonical" href="https://www.54chen.com/posts/49">
    <link href="/favicon.png" rel="icon">
    <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
    <link href="/stylesheets/fkwb.css?v6" type="text/css" rel="stylesheet">  
    <link href="/atom.xml" rel="alternate" title="五四陈科学院" type="application/atom+xml">
    	<link rel="apple-touch-icon" href="touch-icon.png">
  	<link rel="shortcut icon" href="/favicon.ico">
  
    
  
    <style type="text/css">.entry-content table {display: block;width: 100%;overflow: auto;word-break: normal;word-break: keep-all;}.entry-content table th {font-weight: bold;}.entry-content table th,.entry-content table td {padding: 6px 13px;border: 1px solid #ddd;}.entry-content table tr {background-color: #fff;border-top: 1px solid #ccc;}.entry-content table tr:nth-child(2n) {background-color: #f8f8f8;}</style>
  </head>
  
  <body>
    <header role="banner" class="banner_css"><a style="float:left" href="/"><img border="0" src="/images/54chen-logo.gif" alt="五四陈科学院-相信科学，分享技术." title="五四陈科学院-相信科学，分享技术.">
  </a>
  <div>
      <a href="/">首页</a>
      <a href="/blog/archives">归档</a>
      <a href="/video">视频</a>
      <a href="/about">关于</a>
  
      <a href="http://blog.54chen.com" style="color:white;font-size:9px">想找最新内容？</a>
  </div>
  <div class="subscription">
    
  <form action="https://www.54chen.com/cgi" method="get">
    <fieldset role="search">
      
      <input class="search" type="text" name="key" placeholder="Search">
    </fieldset>
  </form>
    
  
  </div>
  
  </header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
    <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
    
  </ul>
    
  <form action="https://www.54chen.com/cgi" method="get">
    <fieldset role="search">
      
      <input class="search" type="text" name="key" placeholder="Search">
    </fieldset>
  </form>
    
    <li><a href="/">Blog</a></li>
    <li><a href="/blog/archives">Archives</a></li>
  
  </nav>
    <div id="main">
      <div id="content">
        <div class="blog-index">
    
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/25/happy-new-year/">Happy New Year!</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-25T00:00:00+08:00" pubdate data-updated="true">2009-01-25 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p><a href="http://www.54chen.com/wp-content/uploads/2009/01/2009.jpg"><img class="alignnone size-full wp-image-429" style="border: 0px;" title="2009" src="http://www.54chen.com/wp-content/uploads/2009/01/2009.jpg" alt="" width="500" height="375"></a></p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/23/%E7%94%A8iptables%E5%81%9A%E6%9C%AC%E6%9C%BA%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/">用iptables做本机端口转发</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-23T00:00:00+08:00" pubdate data-updated="true">2009-01-23 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p>代码如下：
  </p>
<pre>  iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080</pre>
  估计适当增加其它的参数也可以做不同IP的<a href="http://www.54chen.com/c/381">端口</a>转发。
  
  <p>如果需要本机也可以访问，则需要<a href="http://www.54chen.com/c/406">配置</a>OUTPUT链：
  </p>
<pre>  iptables -t nat -A OUTPUT -p tcp --dport 80 -j REDIRECT --to-ports 8080</pre>
  原因：
  
  <p>外网访问需要经过PREROUTING链，但是localhost不经过该链，因此需要用OUTPUT，或者POSTROUTING。</p>
  
  <p>POSTROUTING不行，需要看看。</p>
  
  <p><!-- Saved in parser cache with key pewiki:pcache:idhash:222-0!1!0!!zh-cn!2 and timestamp 20081210025542 --></p>
  
  <p><!-- end content --></p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/19/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84apache%E6%89%A9%E5%B1%95/">如何建立自己的Apache扩展</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-19T00:00:00+08:00" pubdate data-updated="true">2009-01-19 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p> </p>
  
  <p>假设有一个扩展Apache功能的模块<code>mod_foo.c</code> ，使用下列命令，可以将C源程序编译为共享模块，以在运行时加载到Apache服务器中：
  </p>
<div class="example"></div>
  
  <p><code> $ apxs -c mod_foo.c<br>
  /path/to/libtool --mode=compile gcc ... -c mod_foo.c<br>
  /path/to/libtool --mode=link gcc ... -o mod_foo.la mod_foo.slo<br>
  $ _ </code>
  然后，必须修改Apache的配置，以确保有一个<code class="directive">LoadModule </code>指令来加载此共享对象。为了简化这一步骤，<code>apxs</code> 可以自动进行该作，以安装此共享对象到"modules"目录，并更新<code><a href="http://www.54chen.com/c/148">httpd</a>.conf</code> 文件，命令如下：
  </p>
<div class="example"></div>
  
  <p><code> $ apxs -i -a mod_foo.la<br>
  /path/to/instdso.sh mod_foo.la /path/to/apache/modules<br>
  /path/to/libtool --mode=install cp mod_foo.la /path/to/apache/modules       ...       chmod 755 /path/to/apache/modules/mod_foo.so<br>
  [activating module 'foo' in /path/to/apache/conf/httpd.conf]<br>
  $ _ </code>
  如果配置文件中尚不存在，会增加下列的行：
  </p>
<div class="example"></div>
  
  <p><code> LoadModule foo_module modules/mod_foo.so </code>
  如果你希望默认禁用此模块，可以使用 <code>-A</code> 选项，即：
  </p>
<div class="example"></div>
  
  <p><code> $ apxs -i -A mod_foo.c </code>
  要快速测试apxs机制，可以建立一个Apache模块样板及其对应的Makefile ：
  </p>
<div class="example"></div>
  
  <p><code> $ apxs -g -n foo<br>
  Creating [DIR]  foo<br>
  Creating [FILE] foo/Makefile<br>
  Creating [FILE] foo/modules.mk<br>
  Creating [FILE] foo/mod_foo.c<br>
  Creating [FILE] foo/.deps<br>
  $ _ </code>
  然后，立即可以编译此样板模块为共享对象并加载到<a href="http://www.54chen.com/c/26">Apache</a>服务器中：
  </p>
<div class="example"></div>
  
  <p><code> $ cd foo<br>
  $ make all reload<br>
  apxs -c mod_foo.c<br>
  /path/to/libtool --mode=compile gcc ... -c mod_foo.c<br>
  /path/to/libtool --mode=link gcc ... -o mod_foo.la mod_foo.slo<br>
  apxs -i -a -n "foo" mod_foo.la<br>
  /path/to/instdso.sh mod_foo.la /path/to/apache/modules<br>
  /path/to/libtool --mode=install cp mod_foo.la /path/to/apache/modules       ...       chmod 755 /path/to/apache/modules/mod_foo.so<br>
  [activating module 'foo' in /path/to/apache/conf/httpd.conf]<br>
  apachectl restart<br>
  /path/to/apache/sbin/apachectl restart: httpd not running, trying to start<br>
  [Tue Mar 31 11:27:55 1998] [debug] mod_so.c(303): loaded module foo_module<br>
  /path/to/apache/sbin/apachectl restart: httpd started<br>
  $ _</code></p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/17/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E5%BC%95%E8%B5%B7oracle-%E4%B8%8D%E7%A8%B3%E5%AE%9A%E7%9A%84%E9%97%AE%E9%A2%98/">如何解决时间同步引起oracle 不稳定的问题</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-17T00:00:00+08:00" pubdate data-updated="true">2009-01-17 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p>数据库服务器的时间与真实时间一旦出现差异，就要对数据库服务器进行时间同步。很多地方都把ntpdate放到cron中，5分钟自动同步一次。然而，这么做，常常会引会数据库ORA-01555，甚至db crash。</p>
  
  <p>找到一种方法据说可以解决这个问题。即使用ntpd -x来同步时间 instead of　ntpdate。<br>
  实际上ntpd，不只是一种时间服务器的server端，同时也可以做client端，相当于ntpdate。当它做client时，与ntpdate的差别是，ntpdate已近淘汰，ntpd则可看作是它升级版。<br>
  　
  下面的方法是讲如何在linux的环境中设置ntpd：</p>
  
  <p>1. 修改/etc/ntp.conf</p>
  
  <p>2. 加入time server。每个数据库中心都应用会有一组时间服务器，可以找sa要， 比如国际站，加入：</p>
  
  <p>server ntp1.alibaba.com<br>
  server ntp2.alibaba.com<br>
  server ntp3.alibaba.com</p>
  
  <p>ntp.conf有很多参数，都忽略就行。</p>
  
  <p>3. 修改/etc/sysconfig/ntpd， 加入-x参数，变成：</p>
  
  <p>OPTIONS="-U ntp -x -p /var/run/ntpd.pid"</p>
  
  <p>这据说是为db同步所要求的。</p>
  
  <p>4. 首先同步一次时间：<br>
  ntpdate time.nist.gov; hwclock --systohc</p>
  
  <p>如果数据库还要在运行，建议不要这么做。待例行维护时再处理。</p>
  
  <p>5. 然后启动ntpd：<br>
  /etc/init.d/ntpd start</p>
  
  <p>6. 最后加入到自动启动列表：<br>
  chkconfig --level 2345 ntpd on</p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/16/e5-a4-9a-e5-8f-b0slave-e7-9a-84mysql-replication-e7-9a-84-e9-85-8d-e7-bd-ae/">多台slave的mysql Replication的配置</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-16T00:00:00+08:00" pubdate data-updated="true">2009-01-16 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p> 5.1.24版本的配置请看：http://www.masalife.com/archives/173
  </p>
<p align="center"><strong>
  </strong></p>
  
  <p>一、先修改服务器的配置文件</p>
  
  <p>       1、Master服务器配置简单，修改my.cnf为:</p>
  
  <p>       server-id       = 1</p>
  
  <p>log-bin</p>
  
  <p>set-variable=binlog-ignore-db=mysql</p>
  
  <p>2、slave1的配置加入</p>
  
  <p>server-id       = 2</p>
  
  <p>master-host = 172.16.20.135</p>
  
  <p>master-user = rep</p>
  
  <p>master-password = cnrep</p>
  
  <p>master-port = 3306</p>
  
  <p>log-bin</p>
  
  <p>set-variable=replicate-ignore-db=mysql</p>
  
  <p>set-variable=replicate-do-db=AliSMS</p>
  
  <p>set-variable=replicate-do-db=lcd</p>
  
  <p>set-variable=replicate-do-db=loginmanager</p>
  
  <p>set-variable=replicate-do-db=samis</p>
  
  <p>set-variable=replicate-do-db=sareport</p>
  
  <p>set-variable=replicate-do-db=syslog</p>
  
  <p>set-variable=replicate-do-db=web_speed</p>
  
  <p>log-slave-updates</p>
  
  <p>3、slave2服务器的配置</p>
  
  <p>server-id       = 3</p>
  
  <p>master-host = 172.16.20.3</p>
  
  <p>master-user = rep1</p>
  
  <p>master-password = cnrep</p>
  
  <p>master-port = 3306</p>
  
  <p>set-variable=replicate-ignore-db=mysql</p>
  
  <p>set-variable=replicate-do-db=AliSMS</p>
  
  <p>set-variable=replicate-do-db=lcd</p>
  
  <p>set-variable=replicate-do-db=loginmanager</p>
  
  <p>set-variable=replicate-do-db=samis</p>
  
  <p>set-variable=replicate-do-db=sareport</p>
  
  <p>set-variable=replicate-do-db=syslog</p>
  
  <p>set-variable=replicate-do-db=web_speed</p>
  
  <p> </p>
  
  <p>二、重启master数据库</p>
  
  <p> </p>
  
  <p>三、然后锁定master数据库的表：</p>
  
  <p>mysql&gt;FLUSH TABLES WITH READ LOCK;</p>
  
  <p>四、在master数据库中添加用于slave1同步的用户，并赋予相关权限：</p>
  
  <p>mysql&gt;GRANT REPLICATION SLAVE ON *.* TO rep@sa_cfengine1 IDENTIFIED BY 'cnrep';</p>
  
  <p>mysql&gt;GRANT FILE,SELECT,REPLICATION SLAVE ON *.* TO rep@sa_cfengine1 IDENTIFIED BY 'cnrep';</p>
  
  <p> </p>
  
  <p>五、在slave1数据库中添加用于slave2同步的用户，并赋予相关权限：</p>
  
  <p>mysql&gt;GRANT REPLICATION SLAVE ON *.* TO rep1@sa_cfengine2 IDENTIFIED BY 'cnrep';</p>
  
  <p>mysql&gt;GRANT FILE,SELECT,REPLICATION SLAVE ON *.* TO rep1@sa_cfengine2 IDENTIFIED BY 'cnrep';</p>
  
  <p> </p>
  
  <p>六、同步数据库：</p>
  
  <p>方法很多，可以打包之后scp，再解压，由于sa_cfengine1到mysql master服务器通道打通了，切sa_cfengine2到sa_cfengine1通道也打了，故直接scp整个数据库目录即可。</p>
  
  <p>注意：此时要注意删除同步过来的日志文件，最好把与数据库无关的文件全删除（可以将非目录的文件全删了）。</p>
  
  <p> </p>
  
  <p>七、重启salve1的mysql，起来之后锁定表</p>
  
  <p> </p>
  
  <p>八、重启slave2的mysql，然后先后给slave1和master服务器的mysql表解锁</p>
  
  <p>mysql&gt; UNLOCK TABLES；</p>
  
  <p> </p>
  
  <p>九、分别登录slave1和slave2的mysql，查看同步状态：
  </p>
<pre>        mysql&gt;SHOW SLAVE STATUS\G</pre>
  *************************** 1. row ***************************
  
  <p>             Slave_IO_State: Waiting for master to send event</p>
  
  <p>                Master_Host: 172.16.20.135</p>
  
  <p>                Master_User: rep</p>
  
  <p>                Master_Port: 3306</p>
  
  <p>              Connect_Retry: 60</p>
  
  <p>            Master_Log_File: mysql-bin.000051</p>
  
  <p>        Read_Master_Log_Pos: 13856842</p>
  
  <p>             Relay_Log_File: sa_cfengine1-relay-bin.000013</p>
  
  <p>              Relay_Log_Pos: 624419</p>
  
  <p>      Relay_Master_Log_File: mysql-bin.000051</p>
  
  <p><span style="color: #ff0000;">          </span><strong><span style="color: #ff0000;"> Slave_IO_Running: Yes</span></strong></p>
  
  <p><strong><span style="color: #ff0000;">          Slave_SQL_Running: Yes</span></strong></p>
  
  <p>            Replicate_Do_DB: AliSMS,lcd,loginmanager,samis,sareport,syslog,web_speed</p>
  
  <p>        Replicate_Ignore_DB: mysql,mysql</p>
  
  <p>         Replicate_Do_Table:</p>
  
  <p>     Replicate_Ignore_Table:</p>
  
  <p>    Replicate_Wild_Do_Table:</p>
  
  <p>Replicate_Wild_Ignore_Table:</p>
  
  <p>                 Last_Errno: 0</p>
  
  <p>                 Last_Error:</p>
  
  <p>               Skip_Counter: 0</p>
  
  <p>        Exec_Master_Log_Pos: 13856842</p>
  
  <p>            Relay_Log_Space: 624419</p>
  
  <p>            Until_Condition: None</p>
  
  <p>             Until_Log_File:</p>
  
  <p>              Until_Log_Pos: 0</p>
  
  <p>         Master_SSL_Allowed: No</p>
  
  <p>         Master_SSL_CA_File:</p>
  
  <p>         Master_SSL_CA_Path:</p>
  
  <p>            Master_SSL_Cert:</p>
  
  <p>          Master_SSL_Cipher:</p>
  
  <p>             Master_SSL_Key:</p>
  
  <p>      Seconds_Behind_Master: 0</p>
  
  <p>1 row in set (0.01 sec)</p>
  
  <p>注意标注为红色的地方，两个都是yes说明一切正常，否则要检查原因，可以看error log查找原因后做相应的处理。</p>
  
  <p> </p>
  
  <p>十、测试：</p>
  
  <p>       在master数据库中update在同步列表中的一个表的一个字段，如果slave服务器的做相应改变，则测试用过。</p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/15/yahoo%E3%80%81tao%E4%BA%91%E8%AE%A1%E7%AE%97%E5%88%A9%E5%99%A8%E4%B9%8B%E2%80%9C%E4%BA%91%E2%80%9D%E7%AB%AF%E7%9A%84%E5%B0%8F%E9%A3%9E%E8%B1%A1%E2%80%94hadoop/">yahoo、taobao云计算利器之“云”端的小飞象—Hadoop</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-15T00:00:00+08:00" pubdate data-updated="true">2009-01-15 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p> 
  </p>
<p class="MsoNormal" align="center"><strong><span>“云”端的小飞象</span></strong><strong><span lang="EN-US">—Hadoop</span></strong></p>
  <p class="MsoNormal" align="center"><span>孙</span><span> </span><span>牧</span></p>
  
  <p></p>
<h3>
<span lang="EN-US">Hadoop</span><span>简史</span>
</h3>
  <p class="MsoNormal"><span>在搜索技术界，也许有人不熟悉</span><span lang="EN-US">Doug Cutting</span><span>，但很少有人不知道</span><span lang="EN-US">Lucene</span><span>这个著名的全文检索引擎。事实上，</span><span lang="EN-US">Lucene</span><span>应该是</span><span lang="EN-US">Doug Cutting</span><span>的成名作，它被广泛地应用在各种规模的网站和系统中，甚至</span><span lang="EN-US">Eclipse</span><span>中的搜索功能也是</span><span lang="EN-US">Lucene</span><span>来实现的。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>但</span><span lang="EN-US">Doug Cutting</span><span>并没有满足</span><span lang="EN-US">Lucene</span><span>取得的成绩。</span><span lang="EN-US">2002</span><span>年，他发起了一个基于</span><span lang="EN-US">Lucene</span><span>的开源项目</span><span lang="EN-US">Nutch</span><span>，其目标是构建出一个包括网络蜘蛛、文件存储等模块的网页搜索系统。经过</span><span lang="EN-US">2</span><span>年的努力，</span><span lang="EN-US">Nutch</span><span>虽然可以用</span><span lang="EN-US">4</span><span>台机器支持</span><span lang="EN-US">1</span><span>亿网页的抓取和检索，但系统的扩展性开始遇到瓶颈。恰在此时，</span><span lang="EN-US"></span><span>发表了</span><span lang="EN-US">GFS</span><span>、</span><span lang="EN-US">MapReduce</span><span>的论文，这两个创新性的思路点燃了</span><span lang="EN-US">Nutch 2</span><span>名开发人员的斗志，他们又花了</span><span lang="EN-US">2</span><span>年的业余时间实现了</span><span lang="EN-US">DFS</span><span>（分布式文件系统）和</span><span lang="EN-US">MapReduce</span><span>机制，这次改造使</span><span lang="EN-US">Nutch</span><span>可以在</span><span lang="EN-US">20</span><span>台机器上支持几亿的数据规模，其编程和运维的简易性也得到了大幅提升，但系统的吞吐能力与一个真正的网页搜索系统仍有不小的差距。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">2006</span><span>年，开源社区如火如荼，当佬雅虎在思索构建一个高度利用硬件资源、维护和开发都非常简易的软件架构时，</span><span lang="EN-US">Doug Cutting</span><span>和他的</span><span lang="EN-US">Nutch</span><span>进入了他们的视野。一方具有超强的技术前瞻性和实战经验，另一方能提供世界上数一数二的数据、硬件和人力资源，双方一拍即合，同年</span><span lang="EN-US">1</span><span>月</span><span lang="EN-US">Doug Cutting</span><span>正式加入雅虎，</span><span lang="EN-US">2</span><span>月</span><span lang="EN-US">Hadoop</span><span>从</span><span lang="EN-US">Nutch</span><span>中分离出来，正式成为</span><span lang="EN-US">Apache</span><span>组织中一个专注于</span><span lang="EN-US">DFS</span><span>和</span><span lang="EN-US">MapReduce</span><span>的开源项目。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">2008</span><span>年</span><span lang="EN-US">2</span><span>月，又是两年，雅虎宣布搭建出一个世界上最大的基于</span><span lang="EN-US">Hadoop</span><span>的生产集群系统</span><span lang="EN-US">—Yahoo! Search Webmap</span><span>（简单地讲，就是雅虎网页搜索抓取的所有站点和网页及其关系的数据库），下面一组数据可以让我们对该系统的规模有个初步的认识：</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>Ø<span>  </span></span></span><span>页面之间的链接数超过</span><span lang="EN-US">1000</span><span>亿；</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>Ø<span>  </span></span></span><span lang="EN-US">Webmap</span><span>输出的压缩数据超过</span><span lang="EN-US">300TB</span><span>（</span><span lang="EN-US">Terabyte</span><span>）；</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>Ø<span>  </span></span></span><span>有单一的</span><span lang="EN-US">MapReduce</span><span>任务同时在</span><span lang="EN-US">1</span><span>万多个</span><span lang="EN-US">CPU</span><span>的核（</span><span lang="EN-US">core</span><span>）上运行；</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>Ø<span>  </span></span></span><span>生产集群硬盘空间占用超过</span><span lang="EN-US">5PB</span><span>（</span><span lang="EN-US">Petabyte</span><span>）；</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>Ø<span>  </span></span></span><span>与原来没用</span><span lang="EN-US">Hadoop</span><span>的方案相比节约了</span><span lang="EN-US">30%</span><span>的时间。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>这时候，可以说</span><span lang="EN-US">Doug Cutting</span><span>想构建一个</span><span lang="EN-US">Web-scale</span><span>级别系统的心愿也终于实现了！</span></p>
  <p class="MsoNormal"> </p>
  
  <p></p>
<h3>
<span lang="EN-US">Hadoop</span><span>的系统架构</span>
</h3>
  <p class="MsoNormal"><span>简单地讲，</span><span lang="EN-US">Hadoop</span><span>是一个可以更容易开发和并行处理大规模数据的分布式计算平台。它的主要特点是：</span><strong><span>扩容能力（</span></strong><strong><span lang="EN-US">Scalable</span></strong><strong><span>）</span></strong><span>、<strong><span>成本低（</span></strong></span><strong><span lang="EN-US">Economical</span></strong><strong><span>）</span></strong><span>、<strong><span>高效率（</span></strong></span><strong><span lang="EN-US">Efficient</span></strong><strong><span>）</span></strong><span>、<strong><span>可靠性（</span></strong></span><strong><span lang="EN-US">Reliable</span></strong><strong><span>）</span></strong><span>。另外，</span><span lang="EN-US">Hadoop</span><span>是一款完全用</span><span lang="EN-US">Java</span><span>开发的开源软件，因此它可以运行在多种作系统和商用硬件上。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">Hadoop</span><span>主要由两部分构成：</span><span lang="EN-US">Hadoop</span><span>分布式文件系统（</span><span lang="EN-US">HDFS</span><span>）和</span><span lang="EN-US">MapReduce</span><span>的实现。</span></p>
  <p class="MsoNormal"><span lang="EN-US">HDFS</span><span>和</span><span lang="EN-US">MapReduce</span><span>的关系如下图所示：</span></p>
  <p class="MsoNormal" align="center"><a href="http://www.54chen.com/wp-content/uploads/2009/01/1.jpg"><img class="alignnone size-full wp-image-400" title="1" src="http://www.54chen.com/wp-content/uploads/2009/01/1.jpg" alt="" width="405" height="201"></a></p>
  <p class="MsoNormal"><span lang="EN-US">MapReduce</span><span>是依赖于</span><span lang="EN-US">HDFS</span><span>实现的。通常</span><span lang="EN-US">MapReduce</span><span>会将被计算的数据分为很多小块，</span><span lang="EN-US">HDFS</span><span>会将每个块复制若干份以确保系统的可靠性，同时它按照一定的规则将数据块放置在集群中的不同机器上，以便</span><span lang="EN-US">MapReduce</span><span>在数据宿主机器上进行最便捷的计算。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>下面我们再深入一些看看</span><span lang="EN-US">HDFS</span><span>和</span><span lang="EN-US">MapReduce</span><span>的实现细节：</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US">HDFS</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">HDFS</span><span>设计时基于如下的前提和目标：</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>1.<span>         </span></span></span><strong><span>硬件错误是常态而不是异常</span></strong><span>：</span><span lang="EN-US">HDFS</span><span>可能由成百上千的服务器所构成，每个服务器上存储着文件系统的部分数据。任一组件都有可能失效，这意味着总是有一部分</span><span lang="EN-US">HDFS</span><span>的组件是不工作的。因此错误检测和快速、自动的恢复是</span><span lang="EN-US">HDFS</span><span>最核心的架构目标。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>2.<span>         </span></span></span><strong><span>流式数据访问</span></strong><span>：</span><span lang="EN-US">HDFS</span><span>的设计中更多的考虑到了数据批处理，而不是用户交互处理。比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>3.<span>         </span></span></span><strong><span>大规模数据集</span></strong><span>：</span><span lang="EN-US">HDFS</span><span>上的一个典型文件大小一般都在</span><span lang="EN-US">G</span><span>字节至</span><span lang="EN-US">T</span><span>字节。因此，</span><span lang="EN-US">HDFS</span><span>被调节以支持大文件存储，并能提供整体上高的数据传输带宽，能在一个集群里扩展到数百个节点。一个单一的</span><span lang="EN-US">HDFS</span><span>实例应该能支撑数以千万计的文件。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>4.<span>         </span></span></span><strong><span>简单的一致性模型：</span></strong><span lang="EN-US">HDFS</span><span>应用需要一个</span><span lang="EN-US">"</span><span>一次写入多次读取</span><span lang="EN-US">"</span><span>的文件访问模型。文件经过创建、写入和关闭之后就不需要改变。这一假设简化了数据一致性问题，并且使高吞吐量的数据访问成为可能。</span><span lang="EN-US">MapReduce</span><span>应用或者网络爬虫应用都非常适合这个模型。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>5.<span>         </span></span></span><strong><span>移动计算比移动数据更划算：</span></strong><span>一个应用请求的计算，离它作的数据越近就越高效，在数据达到海量级别的时候更是如此。因为这样就能降低网络阻塞的影响，提高系统数据的吞吐量。</span><span lang="EN-US">HDFS</span><span>为应用提供了将计算移动到数据附近的接口。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>6.<span>         </span></span></span><strong><span>异构软硬件平台间的可移植性：</span></strong><span>这种特性方便了</span><span lang="EN-US">HDFS</span><span>作为大规模数据应用平台的推广。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">HDFS</span><span>的系统架构如下图所示：</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">HDFS</span><span>采用</span><span lang="EN-US">Master/Slave</span><span>架构，一个</span><span lang="EN-US">HDFS</span><span>集群是由一个</span><span lang="EN-US">Namenode</span><span>和一定数目的</span><span lang="EN-US">Datanodes</span><span>组成。</span><span lang="EN-US">Namenode</span><span>是一个中心服务器，负责管理文件系统的名字空间（</span><span lang="EN-US">Namespace</span><span>）以及客户端对文件的访问。集群中的</span><span lang="EN-US">Datanode</span><span>一般是一个节点一个，负责管理它所在节点上的存储。</span><span lang="EN-US">HDFS</span><span>暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><a href="http://www.54chen.com/wp-content/uploads/2009/01/2.jpg"><img class="alignnone size-medium wp-image-401" style="border: 0px initial initial;" title="2" src="http://www.54chen.com/wp-content/uploads/2009/01/2-300x207.jpg" alt="" width="300" height="207"></a></p>
  <p class="MsoNormal"><span>从内部看，一个文件其实被分成一个或多个数据块（</span><span lang="EN-US">Block</span><span>），这些块存储在一组</span><span lang="EN-US">Datanode</span><span>上。</span><span lang="EN-US">Namenode</span><span>执行文件系统的名字空间作，比如打开、关闭、重命名文件或目录，它也负责确定数据块到具体</span><span lang="EN-US">Datanode</span><span>节点的映射。</span><span lang="EN-US">Datanode</span><span>负责处理文件系统客户端的读写请求，在</span><span lang="EN-US">Namenode</span><span>的统一调度下进行数据块的创建、删除和复制。</span><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>单一节点的</span><span lang="EN-US">Namenode</span><span>大大简化了系统的架构。</span><span lang="EN-US">Namenode</span><span>负责保管和管理所有的</span><span lang="EN-US">HDFS</span><span>元数据（</span><span lang="EN-US">Metadata</span><span>），因而用户数据就不需要通过</span><span lang="EN-US">Namenode</span><span>（也就是说文件数据的读写是直接在</span><span lang="EN-US">Datanode</span><span>上）。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> <span>从内部看，一个文件其实被分成一个或多个数据块（</span><span lang="EN-US">Block</span><span>），这些块存储在一组</span><span lang="EN-US">Datanode</span><span>上。</span><span lang="EN-US">Namenode</span><span>执行文件系统的名字空间作，比如打开、关闭、重命名文件或目录，它也负责确定数据块到具体</span><span lang="EN-US">Datanode</span><span>节点的映射。</span><span lang="EN-US">Datanode</span><span>负责处理文件系统客户端的读写请求，在</span><span lang="EN-US">Namenode</span><span>的统一调度下进行数据块的创建、删除和复制。</span></span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>单一节点的</span><span lang="EN-US">Namenode</span><span>大大简化了系统的架构。</span><span lang="EN-US">Namenode</span><span>负责保管和管理所有的</span><span lang="EN-US">HDFS</span><span>元数据（</span><span lang="EN-US">Metadata</span><span>），因而用户数据就不需要通过</span><span lang="EN-US">Namenode</span><span>（也就是说文件数据的读写是直接在</span><span lang="EN-US">Datanode</span><span>上）。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US"> </span></strong></p>
  <p class="MsoNormal"><strong><span lang="EN-US">MapReduce</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">MapReduce</span><span>是一种高效的分布式编程模型，同时是一种用于处理和生成大规模数据集的实现方式。其实，现实世界中很多计算任务都可以用这个模型来表达，熟悉</span><span lang="EN-US">Unix Shell</span><span>的同学一定写过类似这样的命令行：</span></p>
  <p class="MsoNormal"><span lang="EN-US">~&gt; cat input | grep xxx | sort | uniq -c | cat &gt; output</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>上面每个管道符中间正好对应了一个典型</span><span lang="EN-US">MapReduce</span><span>的几个阶段：</span></p>
  <p class="MsoNormal"><span lang="EN-US">Input | Map | Shuffle &amp; Sort | Reduce | Output</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>下图表明了这几个阶段的工作流及结构关系：</span></p>
  <p class="MsoNormal" align="center"><a href="http://www.54chen.com/wp-content/uploads/2009/01/3.jpg"><img class="alignnone size-full wp-image-402" title="3" src="http://www.54chen.com/wp-content/uploads/2009/01/3.jpg" alt="" width="346" height="498"></a></p>
  <p class="MsoNormal"><span lang="EN-US"><span>1.<span>       </span></span></span><strong><span lang="EN-US">Input</span></strong><strong><span>：</span></strong><span>一个</span><span lang="EN-US">Hadoop MapReduce</span><span>应用通常需要提供一对通过实现合适的接口或抽象类提供的</span><span lang="EN-US">Map</span><span>和</span><span lang="EN-US">Reduce</span><span>函数，还应该指明输入</span><span lang="EN-US">/</span><span>输出的位置（路径）和其他一些运行参数。此外，此阶段还会把输入目录下的大数据文件切分为若干的数据块。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>2.<span>       </span></span></span><strong><span lang="EN-US">Map</span></strong><strong><span>：</span></strong><span lang="EN-US">MapReduce</span><span>框架把应用作业的输入看为是一组</span><span lang="EN-US">&lt;key, value&gt; </span><span>键值对，在</span><span lang="EN-US">Map</span><span>这个阶段，框架会调用用户自定义的</span><span lang="EN-US">Map</span><span>函数处理每一个</span><span lang="EN-US">&lt;key, value&gt; </span><span>键值对，生成一批新的中间</span><span lang="EN-US">&lt;key, value&gt; </span><span>键值对，这两组键值对的类型可能不同。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>3.<span>       </span></span></span><strong><span lang="EN-US">Shuffle &amp; Sort</span></strong><strong><span>：</span></strong><span>为了保证</span><span lang="EN-US">Reduce</span><span>的输入是</span><span lang="EN-US">Map</span><span>排好序的输出。在</span><span lang="EN-US">Shuffle</span><span>阶段，框架通过</span><span lang="EN-US">HTTP</span><span>为每个</span><span lang="EN-US">Reduce</span><span>获得所有</span><span lang="EN-US">Map</span><span>输出中与之相关的</span><span lang="EN-US">&lt;key, value&gt; </span><span>键值对；而在</span><span lang="EN-US">Sort</span><span>阶段，框架将按照</span><span lang="EN-US">key</span><span>的值对</span><span lang="EN-US">Reduce</span><span>的输入进行分组（因为不同</span><span lang="EN-US">map</span><span>的输出中可能会有相同的</span><span lang="EN-US">key</span><span>）。通常</span><span lang="EN-US">Shuffle</span><span>和</span><span lang="EN-US">Sort</span><span>两个阶段是同时进行的，</span><span lang="EN-US">Reduce</span><span>的输入也是一边被取回，一边被合并的。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>4.<span>       </span></span></span><strong><span lang="EN-US">Reduce</span></strong><strong><span>：</span></strong><span>此阶段会遍历中间数据，对每一个唯一</span><span lang="EN-US">key</span><span>，执行用户自定义的</span><span lang="EN-US">Reduce</span><span>函数（输入参数是</span><span lang="EN-US">&lt;key, (list of values)&gt;</span><span>），输出是新的</span><span lang="EN-US">&lt;key, value&gt; </span><span>键值对。</span></p>
  
  <p><strong><span lang="EN-US">Output</span><span>：</span></strong><span>此阶段会把</span><span lang="EN-US">Reduce</span><span>输出的结果写入输出目录的文件中。这样，一个典型的</span><span lang="EN-US">MapReduce</span><span>过程就结束了。</span>
  </p>
<p class="MsoNormal"><strong><span>这里需要强调两点：</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US"><span>1.<span>       </span></span></span><span>整个过程中，</span><span lang="EN-US">Hadoop</span><span>框架负责任务的调度和监控，以及重新执行已经失败的任务。</span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>2.<span>       </span></span></span><span>虽然</span><span lang="EN-US">Hadoop</span><span>框架是用</span><span lang="EN-US">Java</span><span>实现的，但</span><span lang="EN-US">MapReduce</span><span>应用程序则不一定要用</span><span lang="EN-US"> Java</span><span>来写。比如：</span><span lang="EN-US">Hadoop Streaming</span><span>是一种运行作业的实用工具，它允许用户创建和运行任何可执行程序（例如：</span><span lang="EN-US">Shell</span><span>工具）来做为</span><span lang="EN-US">Map</span><span>和</span><span lang="EN-US">Reduc</span><span>作。另外，</span><span lang="EN-US">Hadoop Pipes</span><span>是一个与</span><span lang="EN-US">SWIG</span><span>兼容的</span><span lang="EN-US">C++ API</span><span>（没有基于</span><span lang="EN-US">JNI</span><span>技术），它也可用于实现</span><span lang="EN-US">Map</span><span>和</span><span lang="EN-US">Reduc</span><span>作。</span></p>
  
  <p></p>
<h3>
<span>基于</span><span lang="EN-US">Hadoop</span><span>的其他开源项目</span>
</h3>
  <p class="MsoNormal"><strong><span lang="NO-BOK">Pig - http://incubator.apache.org/pig/</span></strong></p>
  <p class="MsoNormal"><span lang="NO-BOK">Pig</span><span>是</span><span lang="NO-BOK">Yahoo!</span><span>捐献给</span><span lang="NO-BOK">Apache</span><span>的一个项目，目前还在</span><span lang="NO-BOK">Apache</span><span>孵化器（</span><span lang="NO-BOK">incubator</span><span>）阶段，目前版本是</span><span lang="NO-BOK">V0.1.0</span><span>，但基本功能已经可用了。</span><span lang="NO-BOK">Pig</span><span>是一个基于</span><span lang="NO-BOK">Hadoop</span><span>的大规模数据分析平台，它提供的</span><span lang="NO-BOK">SQL-like</span><span>语言叫</span><span lang="NO-BOK">Pig Latin</span><span>，该语言的编译器会把类</span><span lang="NO-BOK">SQL</span><span>的数据分析请求转换为一系列经过优化处理的</span><span lang="NO-BOK">MapReduce</span><span>运算。</span><span lang="NO-BOK">Pig</span><span>为复杂的海量数据并行计算提供了一个简易的作和编程接口。</span></p>
  <p class="MsoNormal"><span lang="NO-BOK"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US">ZooKeeper - http://hadoop.apache.org/zookeeper/</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US">ZooKeeper</span><span>是</span><span lang="EN-US">Hadoop</span><span>的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组（</span><span lang="EN-US">Group</span><span>）服务等。</span><span lang="EN-US">ZooKeeper</span><span>的目标就是封装好这些复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</span><span lang="EN-US">ZooKeeper</span><span>的一些与</span><span lang="EN-US"></span><span>的</span><span lang="EN-US">Chubby lock service</span><span>很相似。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US">HBase - http://hadoop.apache.org/hbase/</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US">HBase</span><span>也是</span><span lang="EN-US">Hadoop</span><span>的正式子项目，它是一个面向列的分布式数据库，其源于</span><span lang="EN-US"></span><span>的</span><span lang="EN-US">BigTable</span><span>论文。目前该项目的主要开发人员来自刚被</span><span lang="EN-US">Microsoft</span><span>收购的</span><span lang="EN-US">Powerset</span><span>公司。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US">Mahout - http://lucene.apache.org/mahout/</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US">Mahout</span><span>是一个利用</span><span lang="EN-US">Map/Reduce</span><span>的机器学习算法库，其源于斯坦福大学的几个学者在</span><span lang="EN-US">06</span><span>年的</span><span lang="EN-US">nips</span><span>会议上发表的一篇文章</span><span lang="EN-US">"Map-Reduce for Machine Learning on Multicore"</span><span>。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><strong><span lang="EN-US">Hive - http://mirror..com//hive/</span></strong></p>
  <p class="MsoNormal"><span lang="EN-US">Hive</span><span>是</span><span lang="EN-US">Facebook 08</span><span>年</span><span lang="EN-US">8</span><span>月刚开源的一个数据仓库框架，其系统目标与</span><span lang="EN-US">Pig</span><span>有相似之处，但它有一些</span><span lang="EN-US">Pig</span><span>目前还不支持的机制，比如：更丰富的类型系统、更类似</span><span lang="EN-US">SQL</span><span>的查询语言、</span><span lang="EN-US">Table/Partition</span><span>元数据的持久化。目前，</span><span lang="EN-US">Facebook</span><span>已经提交了申请，希望</span><span lang="EN-US">Hive</span><span>成为</span><span lang="EN-US">Hadoop</span><span>的一个贡献项目（</span><span lang="EN-US">contrib project</span><span>）。</span></p>
  
  <p></p>
<h3>
<span>有谁在用</span><span lang="EN-US">Hadoop</span><span>？</span>
</h3>
  <p class="MsoNormal"><span>在</span><span lang="EN-US">Yahoo!</span><span>，</span><span lang="EN-US">Hadoop</span><span>目前除了被用于网页搜索中的</span><span lang="EN-US">Webmap</span><span>中，还广泛地被用到</span><span lang="EN-US">Yahoo</span><span>！的日志分析、广告计算、科研实验中。另外，</span><span lang="EN-US">2007</span><span>年年底</span><span lang="EN-US">Yahoo!</span><span>和卡耐基</span><span lang="EN-US">-</span><span>梅隆大学发起的</span><span lang="EN-US">Open Academic Clusters--M45</span><span>，至今已经发展为</span><span lang="EN-US">500</span><span>多台的集群，并完成了多个颇具学术价值的项目。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span lang="EN-US">Amazon</span><span>的搜索门户</span><span lang="EN-US">A9.com</span><span>中的商品搜索的索引生成就是基于</span><span lang="EN-US">Hadoop</span><span>完成的。另外，</span><span lang="EN-US">Amazon</span><span>最近发布的</span><span lang="EN-US">GrepTheWeb Web Service</span><span>，内部使用了基于</span><span lang="EN-US">EC2</span><span>（</span><span lang="EN-US">Elastic Compute Cloud</span><span>）的</span><span lang="EN-US">Hadoop</span><span>集群，承担其中的并行计算工作。</span></p>
  <p class="MsoNormal"><span lang="EN-US"> </span></p>
  <p class="MsoNormal"><span>著名</span><span lang="EN-US">SNS</span><span>网站</span><span lang="EN-US">Facebook</span><span>用</span><span lang="EN-US">Hadoop</span><span>构建了整个网站的数据仓库，它目前有</span><span lang="EN-US">320</span><span>多台机器进行网站的日志分析和数据挖掘。此外，在</span><span lang="EN-US">IBM 2007</span><span>年年底的蓝云计算集群中也采用了</span><span lang="EN-US">Hadoop</span><span>进行并行计算。</span></p>
  
  <p></p>
<h3><span>展望</span></h3>
  <p class="MsoNormal"><span>必须承认，在</span><span lang="EN-US">Hadoop</span><span>及其相关的开源项目中，可以看到</span><span lang="EN-US"></span><span>系统架构中核心要素</span><span lang="EN-US">GFS</span><span>、</span><span lang="EN-US">MapReduce</span><span>、</span><span lang="EN-US">BigTable</span><span>、</span><span lang="EN-US">Sawzall</span><span>、</span><span lang="EN-US">Chubby</span><span>的身影。因此，从某个角度来说，</span><span lang="EN-US">Hadoop</span><span>目前还是一个模仿者、跟随者。当大家看到这篇文章时，</span><span lang="EN-US">Hadoop</span><span>应该已经发布</span><span lang="EN-US">0.18</span><span>了，从版本号来看，无疑</span><span lang="EN-US">Hadoop</span><span>还是一只幼年的小飞象，但就是这只看似笨拙的小飞象，却承载着</span><span lang="EN-US">Doug Cutting</span><span>及其伙伴坚持不懈的努力和造福开源社区的决心。因此，我们有理由相信，在“云计算”时代即将来临之际，</span><span lang="EN-US">Hadoop</span><span>所营造的一个软件生态系统，必将成为一个最符合“、平等和分享”的互联网的云计算实践平台。</span></p>
  
  <p></p>
<h3><span>参考链接</span></h3>
  <p class="MsoNormal"><span lang="EN-US"><span>1.<span>         </span></span></span><span lang="EN-US">Hadoop</span><span>项目主页：</span><span lang="EN-US"><a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>2.<span>         </span></span></span><span>更多的</span><span lang="EN-US">Hadoop</span><span>应用案例：</span><span lang="EN-US"><a href="http://wiki.apache.org/hadoop/PoweredBy">http://wiki.apache.org/hadoop/PoweredBy</a></span></p>
  <p class="MsoNormal"><span lang="EN-US"><span>3.<span>         </span></span></span><span lang="EN-US">Yahoo</span><span>！</span><span lang="EN-US">Hadoop</span><span>研发团队的</span><span lang="EN-US">Blog</span><span>：</span><span lang="EN-US"><a href="http://developer.yahoo.com/blogs/hadoop">http://developer.yahoo.com/blogs/hadoop</a></span></p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/12/%E5%8F%B0%E6%B9%BE%E7%9A%84%E9%9B%B6%E8%9B%8B%E6%9C%88%E5%8F%B0/">台湾的零蛋月台</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-12T00:00:00+08:00" pubdate data-updated="true">2009-01-12 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p><a href="http://www.54chen.com/c/230">搜索一下</a>“零蛋”搜索出来的照片，很拉风的样子，向作者致敬，不知道这简体台湾同胞看得懂不。</p>
  
  <p>一二三 到臺灣 臺灣有個阿里山</p>
  
  <p>有图为证。</p>
  
  <p><a href="http://www.54chen.com/wp-content/uploads/2009/01/3024624937_76d9b601a3.jpg"><img class="alignnone size-full wp-image-396" title="3024624937_76d9b601a3" src="http://www.54chen.com/wp-content/uploads/2009/01/3024624937_76d9b601a3.jpg" alt="" width="411" height="500" border="0"></a></p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/08/51ditu-webgis-postgresql-postgregis/">51ditu等网站技术揭秘-利用开源框架搭建一整套的WEBGIS</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-08T00:00:00+08:00" pubdate data-updated="true">2009-01-08 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p>[文章作者：陈臻 本文版本：v1.0 最后修改：2009.1.8 转载请注明原文链接：<a href="http://www.54chen.com/c/387">http://www.54chen.com/c/387</a>]</p>
  
  <p>感谢老早前李兄做的tech talk，一直有人在问及51ditu和mapbar什么的都怎么做的，老是记不住这些开源的东东都什么名字，特做下记录。</p>
  
  <p>下图是一个完整的方案图：</p>
  
  <p><a href="http://www.54chen.com/wp-content/uploads/2009/01/e59bbee789871.jpg"><img class="alignnone size-full wp-image-388" title="e59bbee789871" src="http://www.54chen.com/wp-content/uploads/2009/01/e59bbee789871.jpg" alt="" width="500" height="185"></a></p>
  
  <p>其中所涉及的开源技术有：
  </p>
<h4> 
  </h4>
<table border="1" cellspacing="0" cellpadding="0" width="548">
<colgroup span="1">
<col span="2" width="152">
<col span="1" width="128">
<col span="1" width="160">
<col span="1" width="256">
</colgroup>
  <tbody></tbody>
  <tbody>
  <tr height="96">
  <td class="oa1" width="152" height="96"><span>软件名称</span></td>
  <td class="oa2" width="152">
<span>License</span> <span>类型</span>
</td>
  <td class="oa2" width="128">
<span>编程</span> <span>语言</span>
</td>
  <td class="oa2" width="160"><span>运行环境</span></td>
  <td class="oa3" width="256"><span>用途</span></td>
  </tr>
  <tr height="48">
  <td class="oa4" width="152" height="48"><span>PostGIS</span></td>
  <td class="oa5" width="152"><span>GPL</span></td>
  <td class="oa5" width="128"><span>Plpgsql</span></td>
  <td class="oa5" width="160"><span>Postgresql</span></td>
  <td class="oa6" width="256"><span>存储数据</span></td>
  </tr>
  <tr height="67">
  <td class="oa4" width="152" height="67"><span>MapServer</span></td>
  <td class="oa5" width="152">
<span>MapServer</span><span> License</span>
</td>
  <td class="oa5" width="128"><span>C++</span></td>
  <td class="oa5" width="160"><span>UNIX like/ Windows</span></td>
  <td class="oa6" width="256"><span>提供地图相关服务</span></td>
  </tr>
  <tr height="67">
  <td class="oa4" width="152" height="67"><span>TileCache</span></td>
  <td class="oa5" width="152"><span>BSD</span></td>
  <td class="oa5" width="128"><span>Python</span></td>
  <td class="oa5" width="160"><span>All Platform</span></td>
  <td class="oa6" width="256"><span>图片缓存</span></td>
  </tr>
  <tr height="66">
  <td class="oa4" width="152" height="66"><span>OpenLayers</span></td>
  <td class="oa5" width="152"><span>BSD</span></td>
  <td class="oa5" width="128">
<span>Javascript</span><span> </span>
</td>
  <td class="oa5" width="160"><span>IE/Firefox</span></td>
  <td class="oa6" width="256"><span>客户端展现控制</span></td>
  </tr>
  <tr height="67">
  <td class="oa7" width="152" height="67"><span>GDAL/OGR</span></td>
  <td class="oa8" width="152"><span>MIT License</span></td>
  <td class="oa8" width="128"><span>C++</span></td>
  <td class="oa8" width="160"><span>UNIX like/ Windows</span></td>
  <td class="oa9" width="256"><span>数据格式导换</span></td>
  </tr>
  </tbody>
</table>
  
  <h4>再简单解释下：</h4>
  1.PostGis是PGSQL的一个扩展，<span>在遵循</span><span>OpenGIS</span><span>规范下，提供空间对象、空间索引、空间作函数和空间作符等空间信息服务功能。</span>
  
  <p>2.MapServer可以提供openGIS规范的各种接口。</p>
  
  <p>3.<span>MapServer</span><span>根据参数中指定的路径读取</span><span>mapfile</span><span>文件和</span><span>SLD</span><span>文件。</span></p>
  
  <p>4.<span>使用</span><span>SLD(Styled Layer Descriptors ), </span><span>Mapfile</span><span>控制地图显示样式。</span></p>
  
  <p>5.<span>根据</span><span>SLD</span><span>和</span><span>mapfile</span><span>的样式参数</span><span>,</span><span>配合</span><span>GD(Graphics Library)</span><span>进行的图形制作。</span></p>
  
  <p>6.查询只与pgsql有关</p>
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/07/eclipse%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95jboss%E5%BA%94%E7%94%A8%E8%AE%BE%E7%BD%AE/">Eclipse远程调试JBoss应用设置(linux&amp;win版本)</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-07T00:00:00+08:00" pubdate data-updated="true">2009-01-07 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p></p>
<ul>
  	<li>修改<a href="http://www.54chen.com/c/364">JBoss</a>启动配置</li>
  </ul>
  打开JBOSS_HOME/bin目录下的run.conf文件，找到：
  
  <p> #JAVA_OPTS="$JAVA_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=y"</p>
  
  <p>将其修改为：</p>
  
  <p> JAVA_OPTS="$JAVA_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,address=8787,server=y,suspend=n"</p>
  
  <p>(最后的y改成n)</p>
  
  <p>其中：8787为调试的端口号；</p>
  
  <p><strong>WIN:</strong></p>
  
  <p>直接修改run.bat，找到这一行，删除前面的rem，修改suspend为n。
  </p>
<ul>
  	<li> 启动JBoss</li>
  </ul>
   ./run.sh -b192.168.1.x
  
  <p>其中192.168.1.x是Jboss所在机器的ip；
  </p>
<ul>
  	<li>新建调试配置</li>
  </ul>
  在Eclipse中，<a href="http://www.54chen.com/c/47">打开</a>菜单“run”-〉“debug configurations...”；在出现的对话框中，选择“Remote Java Application”，右键单击，在弹出的菜单中选择“New”，在出现的对话框的“host”中输入Jboss<a href="http://www.54chen.com/c/379">服务器</a>的ip（192.168.1.x），在“port”中输入调试的端口号（8787），选择“debug”开始调试；
  <ul>
  	<li>  调试</li>
  </ul>
  在出现的“debug view”中，打开需要调试的<a href="http://www.54chen.com/c/354">Java</a>源文件，设置相应的断点就可以了
  </div>
    
    
  
  
      </article>
    
    
      <article>
        
    <header>
      
        <h1 class="entry-title"><a href="/blog/2009/01/06/%E8%BD%BB%E7%82%B9%E9%AD%94%E6%A3%92%EF%BC%8C%E7%9E%AC%E9%97%B4%E5%AE%89%E8%A3%85%E4%B8%8A%E7%99%BE%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/">轻点魔棒，瞬间安装上百台服务器</a></h1>
      
      
        <p class="meta">
          
  
  
  
  
  
  
  
  
    
  
  
  
  <time datetime="2009-01-06T00:00:00+08:00" pubdate data-updated="true">2009-01-06 00:00:00 +0800</time>
          
        </p>
      
    </header>
  
  
    <div class="entry-content entry-content1">
<p>转自: 知道分子<a href="http://www.blogger.com/profile/00767221594564607162" target="_blank">查看完整个人资料</a>  <a href="http://hutuworm.blogspot.com/" target="_blank">http://hutuworm.blogspot.com</a></p>
  
  <p> </p>
  
  <p>从前，我们一直在做装机民工这份很有前途的职业。自打若干年前 Red Hat 推出了Kickstart，此后我们顿觉身价倍增。不再需要刻了光盘一台一台地安装 <a href="http://www.54chen.com/c/356">Linux</a>，只要搞定PXE、DHCP、TFTP，还有那满屏眼花缭乱不知所云的 Kickstart脚本，我们就可以像哈里波特一样，轻点魔棒，瞬间安装上百台服务器。这一堆花里胡哨的东西可不是一般人都能整明白的，没有大专以上学 历，通不过英语四级，根本别想玩转。总而言之，这是一份多么有前途，多么有技术含量的工作啊。</p>
  
  <p>很不幸，Red Hat 最新发布了网络安装服务器套件Cobbler（补鞋匠），它已将 <a href="http://www.54chen.com/c/356">Linux</a>网络安装的技术门槛，从大专以上文化水平，成功降低到初中以下，连补鞋匠都能学会。对于我们这些在装机领域浸淫多年，经验丰富，老骥伏枥，志在 千里的民工兄弟们来说，不啻为一个晴天霹雳（}雷{）。</p>
  
  <p>Cobbler（<a href="https://fedorahosted.org/cobbler" target="_blank">https://fedorahosted.org/cobbler</a>）声称可以快速建立网络安装<a href="http://www.54chen.com/c/372">环境</a>（rapid setup ofnetwork installation environments），那么到底有多快呢？我在一台装有 Fedora 9的服务器上进行了测试，步骤如下：</p>
  
  <p>1. 安装相关软件：<br>
       yum -y install cobbler tftp-server dhcp httpd xinetd     # 注意 /var/www/cobbler 目录必须具有足够容纳 Linux 安装文件的空间（移动，建软链接）</p>
  
  <p>2. 检查 cobbler <span class="t_tag" onclick="tagshow(event)">配置</span>：<br>
       cobbler check   # 按提示解决相关问题，把 /etc/cobbler/settings 中的 server 和  next_server 设为本服务器的 IP 地址，manage_dhcp 设为 1，以便管理 DHCP</p>
  
  <p>3. 导入 Fedora 9 安装 DVD ISO 中的文件：<br>
       mount -o loop Fedora9/x86_64/Fedora-9-x86_64-DVD.iso /mnt/dvd/    # 将ISO文件挂载到 /mnt/dvd 目录<br>
       cobbler import --mirror=/mnt/dvd --name=FC9-x86-64      # 从 /mnt/dvd 目录导入所有安装文件，命名为 FC9-x86-64<br>
       cobbler distro list          # 查看导入结果，应显示 FC9-64-i386 和 FC9-64-xen-i386</p>
  
  <p>4. 修改 DHCP 和 Kickstart 配置模板：<br>
       vi /etc/cobbler/dhcp.template        # DHCP 配置模板，如果已经有一个 dhcpd.conf，可参照修改此模板<br>
       vi /etc/cobbler/sample.ks            # Kickstart 配置模板</p>
  
  <p>5. 生成并同步所有配置：<br>
       cobbler sync</p>
  
  <p>6. 启动相关服务：<br>
       service xinetd start               # /etc/xinetd.d/tftp 中 disable = no<br>
       service dhcpd start<br>
       service cobblerd start</p>
  
  <p>曹植七步成诗，而 Cobbler 居然只需要六步。启动另一台新服务器，通过 PXE 启动进入蓝色的 Cobbler 安装界面，选择 Fedora 9 安装项，几分钟之内就能一气呵成，自动完成<span class="t_tag" onclick="tagshow(event)">系统</span>安装。[OVER] </p>
  </div>
    
    
  
  
      </article>
    
  
  
  <div class="pagination">
    
      <a href="/posts/48">« Prev</a>
    
  
    
      
        <a href="/">1</a>
      
    
      
        <a href="/posts/2">2</a>
      
    
      
        <a href="/posts/3">3</a>
      
    
      
        <a href="/posts/4">4</a>
      
    
      
        <a href="/posts/5">5</a>
      
    
      
        <a href="/posts/6">6</a>
      
    
      
        <a href="/posts/7">7</a>
      
    
      
        <a href="/posts/8">8</a>
      
    
      
        <a href="/posts/9">9</a>
      
    
      
        <a href="/posts/10">10</a>
      
    
      
        <a href="/posts/11">11</a>
      
    
      
        <a href="/posts/12">12</a>
      
    
      
        <a href="/posts/13">13</a>
      
    
      
        <a href="/posts/14">14</a>
      
    
      
        <a href="/posts/15">15</a>
      
    
      
        <a href="/posts/16">16</a>
      
    
      
        <a href="/posts/17">17</a>
      
    
      
        <a href="/posts/18">18</a>
      
    
      
        <a href="/posts/19">19</a>
      
    
      
        <a href="/posts/20">20</a>
      
    
      
        <a href="/posts/21">21</a>
      
    
      
        <a href="/posts/22">22</a>
      
    
      
        <a href="/posts/23">23</a>
      
    
      
        <a href="/posts/24">24</a>
      
    
      
        <a href="/posts/25">25</a>
      
    
      
        <a href="/posts/26">26</a>
      
    
      
        <a href="/posts/27">27</a>
      
    
      
        <a href="/posts/28">28</a>
      
    
      
        <a href="/posts/29">29</a>
      
    
      
        <a href="/posts/30">30</a>
      
    
      
        <a href="/posts/31">31</a>
      
    
      
        <a href="/posts/32">32</a>
      
    
      
        <a href="/posts/33">33</a>
      
    
      
        <a href="/posts/34">34</a>
      
    
      
        <a href="/posts/35">35</a>
      
    
      
        <a href="/posts/36">36</a>
      
    
      
        <a href="/posts/37">37</a>
      
    
      
        <a href="/posts/38">38</a>
      
    
      
        <a href="/posts/39">39</a>
      
    
      
        <a href="/posts/40">40</a>
      
    
      
        <a href="/posts/41">41</a>
      
    
      
        <a href="/posts/42">42</a>
      
    
      
        <a href="/posts/43">43</a>
      
    
      
        <a href="/posts/44">44</a>
      
    
      
        <a href="/posts/45">45</a>
      
    
      
        <a href="/posts/46">46</a>
      
    
      
        <a href="/posts/47">47</a>
      
    
      
        <a href="/posts/48">48</a>
      
    
      
        <em>49</em>
      
    
      
        <a href="/posts/50">50</a>
      
    
      
        <a href="/posts/51">51</a>
      
    
      
        <a href="/posts/52">52</a>
      
    
      
        <a href="/posts/53">53</a>
      
    
      
        <a href="/posts/54">54</a>
      
    
      
        <a href="/posts/55">55</a>
      
    
      
        <a href="/posts/56">56</a>
      
    
  
    
      <a href="/posts/50">Next »</a>
    
  </div>
  
  
    <div class="pagination">
      <a href="/blog/archives">Blog Archives</a>
    </div>
  </div>
  <aside class="sidebar">
    
      
    
  </aside>
  
    </div>
    <footer role="contentinfo" class="footer_css">  <script src="/javascripts/modernizr-2.0.js"></script>
    <script src="/javascripts/libs/jquery.min.js"></script>
    <script src="/javascripts/octopress.js" type="text/javascript"></script>
    Copyright © 2017 - 54chen -
  
  </footer>
    
  
  
  
  
  
  
  
  
  
  </div>
</body>
  </html>
